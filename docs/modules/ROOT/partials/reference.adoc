= ModelRouter CRD Reference

== Overview

The ModelRouter custom resource defines an AI model gateway that routes requests to multiple LLM providers through a unified interface.

== Example

[source,yaml]
----
apiVersion: gateway.agentic-layer.ai/v1alpha1
kind: ModelRouter
metadata:
  name: my-litellm-router
  namespace: default
spec:
  type: litellm
  port: 4000
  aiModels:
    - name: openai/gpt-3.5-turbo
    - name: gemini/gemini-2.5-flash
----

== Required Specification Fields

=== spec.type
**Type**: `string` +

Specifies the type of model router implementation. Currently supports:

- `litellm` - LiteLLM proxy implementation


=== spec.aiModels
**Type**: `[]AiModel` +

List of AI models to be made available through the router. Each model must specify a name in the format `provider/model-name`.

See https://docs.litellm.ai/docs/providers for a list of supported providers.
