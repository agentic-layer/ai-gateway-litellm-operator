////
How-To Guides

Add a how-to guide when you're documenting the steps to solve a specific, common problem. These are short, focused checklists for developers who already know the basics.

When to write one: Answering a specific question like "How do I add a custom tool?" or "How do I configure retries?".

Think: A recipe to solve one problem.
////
:repo-name: agentic-layer/ai-gateway-litellm

== Getting Started

=== Prerequisites

Before working with this project, ensure you have the following tools installed on your system:

* **Go**: version 1.24.0 or higher
* **Docker**: version 20.10+ (or a compatible alternative like Podman)
* **kubectl**: The Kubernetes command-line tool
* **kind**: For running Kubernetes locally in Docker
* **make**: The build automation tool

=== Setup Local Environment

[source,shell]
----
# Create a local Kubernetes cluster using kind
kind create cluster
----

[source,bash]
----
# Install cert-manager for webhook support (update the version to the latest stable if needed)
kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.18.2/cert-manager.yaml
# Wait for cert-manager to be ready
kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=cert-manager -n cert-manager --timeout=60s
----

=== Installation

[source,bash]
----
# Install the AI Gateway Litellm operator (update the version to the latest stable if needed)
kubectl apply -f https://github.com/agentic-layer/ai-gateway-litellm/releases/download/v0.0.6/install.yaml
# Wait for the operator to be ready
kubectl wait --for=condition=Available --timeout=60s -n ai-gateway-litellm-system deployment/ai-gateway-litellm-controller-manager
----


== Deploy a LiteLLM ModelRouter

This guide walks you through deploying a LiteLLM instance using the ModelRouter custom resource.

=== Create API Key Secret

First, create a secret containing credentials for the LLM providers you plan to use:

[source,bash]
----
kubectl create secret generic litellm-secrets \
  --from-literal=OPENAI_API_KEY=$OPENAI_API_KEY \
  --from-literal=GEMINI_API_KEY=$GEMINI_API_KEY \
  --from-literal=ANTHROPIC_API_KEY=$ANTHROPIC_API_KEY
----

NOTE: The secret name must match the value configured in the operator. The default expected name is `litellm-secrets`. API keys that are not provided will not cause deployment failures - the corresponding models just won't be available.

=== Create a ModelRouter Resource

. Create a ModelRouter resource file:
+
[source,yaml]
----
apiVersion: gateway.agentic-layer.ai/v1alpha1
kind: ModelRouter
metadata:
  name: my-litellm
spec:
  type: litellm
  aiModels:
    - name: openai/gpt-3.5-turbo
    - name: gemini/gemini-1.5-pro
----

. Apply the configuration:
+
[source,bash]
----
kubectl apply -f my-modelrouter.yaml
----

=== Verify the Deployment

. Check the ModelRouter status:
+
[source,bash]
----
kubectl get modelrouters my-litellm -o yaml
----

. Verify the created resources:
+
[source,bash]
----
# Check the deployment created by the operator
kubectl get deployments -l app=my-litellm

# Check the service
kubectl get services -l app=my-litellm

# Check the configmap with LiteLLM configuration
kubectl get configmaps my-litellm-config
----

. Check the pod logs to ensure LiteLLM started successfully:
+
[source,bash]
----
kubectl logs -l app=my-litellm -c litellm
----
